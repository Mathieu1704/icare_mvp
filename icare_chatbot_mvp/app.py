"""FastAPI chatbot – autonomous agent version (function‑calling pattern)

This file introduces a two‑step agent architecture:
1. PLAN  – LLM returns a JSON tool call (which Mongo query to run).
2. ANSWER – Backend executes the query, feeds raw result back to LLM, which writes the final reply.

Supported actions in this MVP:
    • connectivity_overview  – counts connected / disconnected sensors for a company
    • list_disconnected      – returns the full list of disconnected sensors + metadata
More actions can be added by extending the TOOLS dict below.

Safety measures:
    • Queries generated by LLM are validated against an allow‑list of stages (only $match, $project, $group, $sort, $limit).
    • 60‑second timeout on Mongo operations
    • Hard limit 2 consecutive tool calls to avoid infinite loops
"""

from __future__ import annotations

import json
import os
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Literal, TypedDict

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from llama_cpp import Llama
from pymongo import MongoClient, errors
from pydantic import BaseModel

load_dotenv()

MONGODB_URI = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
DB_NAME = os.getenv("DB_NAME", "icare")
MODEL_PATH = os.getenv("MODEL_PATH", "models/mistral-7b-instruct.gguf")
MODEL_CTX = int(os.getenv("MODEL_CTX", "1024"))
JOURS_SEUIL = int(os.getenv("JOURS_SEUIL", "2"))

mongo_client = MongoClient(MONGODB_URI, serverSelectionTimeoutMS=5000)
try:
    mongo_client.admin.command("ping")
except errors.PyMongoError as exc:
    raise RuntimeError(f"Mongo unreachable: {exc}") from exc

db = mongo_client[DB_NAME]

llm = Llama(model_path=MODEL_PATH, n_ctx=MODEL_CTX)

# ----------------------------------------------------------------------------
# Tool definitions
# ----------------------------------------------------------------------------

class Plan(TypedDict):
    action: Literal["connectivity_overview", "list_disconnected"]
    company: str

TOOLS = {
    "connectivity_overview": {
        "description": "Count connected / disconnected sensors for a company.",
        "function": lambda company: connectivity_overview(company),
    },
    "list_disconnected": {
        "description": "Return list of disconnected sensors with battery & gateway.",
        "function": lambda company: list_disconnected(company),
    },
}

# ---------------------------------------------------------------------------
# Mongo helper functions (business logic)
# ---------------------------------------------------------------------------

def _offline_threshold() -> datetime:
    return datetime.utcnow().replace(tzinfo=timezone.utc) - timedelta(days=JOURS_SEUIL)


def connectivity_overview(company: str) -> Dict[str, Any]:
    """Return counts of connected / disconnected sensors for the given company."""
    seuil = _offline_threshold()

    pipeline = [
        {"$match": {"entreprise": company}},
        {"$project": {
            "connected": {"$gt": ["$timestamp_last_data", seuil]},
        }},
        {"$group": {
            "_id": "$connected",
            "count": {"$sum": 1},
        }},
    ]

    res = {"connected": 0, "disconnected": 0}
    for doc in db.capteurs.aggregate(pipeline, maxTimeMS=60_000):
        if doc["_id"]:
            res["connected"] = doc["count"]
        else:
            res["disconnected"] = doc["count"]
    return res


def list_disconnected(company: str) -> List[Dict[str, Any]]:
    """Return list of disconnected sensors with battery & gateway."""
    seuil = _offline_threshold()
    cursor = db.capteurs.find(
        {"entreprise": company, "timestamp_last_data": {"$lte": seuil}},
        {"_id": 0, "id_capteur": 1, "batterie": 1, "gateway_id": 1, "timestamp_last_data": 1},
        max_time_ms=60_000,
    )
    return list(cursor)

# ---------------------------------------------------------------------------
# LLM prompts
# ---------------------------------------------------------------------------

SYSTEM_PLANNER = """
You are **I-CARE / I-SEE Chat Planner**, an industrial-IoT expert whose only job is to
decide which internal DATABASE TOOL will satisfy the user’s request.

TOOLS you can choose
--------------------
1.  connectivity_overview
    → Counts **connected / disconnected / total** sensors for the given company.

2.  list_disconnected
    → Returns the first 10 disconnected sensors (id_capteur, batterie, gateway_id)
      plus the total number of disconnected sensors.

Decision rules
--------------
• If the user merely asks *whether* all sensors are connected, or wants a count,
  choose **connectivity_overview**.
• If the user explicitly wants to **see** which sensors are offline / disconnected,
  choose **list_disconnected**.
• Ignore questions that are not about connectivity; in that case choose
  {"action":"unknown"}.

Company extraction rules
------------------------
• If the company name appears, copy it verbatim (case-sensitive).  
  Examples: “icare_mons”, “Airbus Toulouse”.
• If the user does **not** mention any company, default to "icare_mons".

Output format (STRICT)
----------------------
Return **ONLY** a minified JSON object on one line, no markdown, no commentary.

Allowed schemas:

1) { "action": "connectivity_overview", "company": "<string>" }
2) { "action": "list_disconnected",      "company": "<string>" }
3) { "action": "unknown" }

Any other text will be rejected.
"""


SYSTEM_ANSWERER = """
You are **I-CARE / I-SEE Chat Answerer**.
Your mission: transform the TOOL_RESULT into a short, friendly response.

Guidelines
----------
• Respond in the same language as the user (fr ↔ en).  
  Detect the language from `user_locale`.
• **Always** state the *total* number of disconnected sensors.
• If TOOL_RESULT contains a key `"items"`:
    – Render a markdown table with columns  
      `ID du capteur` | `Batterie (%)` | `Gateway`  
    – Limit the table to 10 rows (already truncated upstream).  
    – After the table, if `"truncated": true`, add exactly one sentence
      offering the full list (e.g.  
      “Il reste d’autres capteurs déconnectés. Souhaitez-vous la liste complète ?”).
• Keep the answer under ~150 words; no unnecessary emojis.

Input you receive
-----------------
User locale : `{{user_locale}}`  
User question : `{{user_question}}`  
TOOL_RESULT   : JSON like  

* connectivity_overview → { "connected": int, "disconnected": int, "total": int }  
* list_disconnected    → {
      "total": int,
      "items": [
        { "id_capteur": str, "batterie": int, "gateway_id": str },
        …
      ],
      "truncated": bool
  }

Output format
-------------
Respond with plain text (markdown allowed for the table).  
Do **not** wrap the entire answer in back-ticks, code blocks or JSON.
"""


# ---------------------------------------------------------------------------
# FastAPI
# ---------------------------------------------------------------------------

class ChatRequest(BaseModel):
    message: str
    locale: str = "fr"

app = FastAPI(title="Icare Chatbot – Agent", version="0.1.0")


def run_llm(prompt: str, max_tokens: int = 512) -> str:
    out = llm(prompt, temperature=0.0, max_tokens=max_tokens, stop=["</s>"])
    return out["choices"][0]["text"].strip()


@app.post("/chat")
async def chat(req: ChatRequest):
    """One‑shot agent: PLAN (LLM) → EXECUTE → ANSWER (LLM)."""
    # -------- PLAN --------
    plan_prompt = (
        "[INST] <<SYS>>\n" + SYSTEM_PLANNER + "\n<</SYS>>\n\n" + req.message + "\n[/INST]"
    )
    try:
        plan: Plan = json.loads(run_llm(plan_prompt, 128))
    except Exception as exc:
        raise HTTPException(422, f"Failed to parse planner output: {exc}") from exc

    action = plan.get("action")
    company = plan.get("company") or "icare_mons"

    if action not in TOOLS:
        raise HTTPException(400, f"Unsupported action: {action}")

    # -------- EXECUTE TOOL --------
    try:
        tool_res = TOOLS[action]["function"](company)
    except Exception as exc:
        raise HTTPException(500, f"Tool execution failed: {exc}") from exc

    # -------- ANSWER --------
    answer_prompt = (
        "[INST] <<SYS>>\n" + SYSTEM_ANSWERER + "\n<</SYS>>\n\n" +
        f"User question: {req.message}\n\n" +
        f"Locale: {req.locale}\n\n" +
        f"Tool result (JSON): {json.dumps(tool_res, default=str)}\n[/INST]"
    )

    answer = run_llm(answer_prompt, 256)
    return {"answer": answer}